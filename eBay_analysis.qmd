---
title: "eBay Auction Analysis"
author: "MISY 441-172"
date: today
format:
  html:
    toc: true
    toc-depth: 3
    code-fold: false
    theme: cosmo
execute:
  warning: false
  message: false
jupyter: python3
---

## Quick Navigation {.unnumbered}

| **Data Exploration** | **Data Preparation** | **Modeling** |
|:---------------------|:---------------------|:-------------|
| [Business Problem](#business-problem) | [Part e: Convert to Category](#part-e-converting-variables-to-category-type) | [Model 1: All Variables](#modeling-part-1-logistic-regression-with-all-variables) |
| [Part a: Load Data](#part-a-import-packages-and-load-data) | [Part f: Dummy Variables](#part-f-creating-dummy-variables) | [Model 2: Confusion Matrix](#modeling-part-2-confusion-matrix-and-accuracy) |
| [Part b: Observe Variables](#part-b-observe-variables-in-the-dataset) | [Part g: Outlier Analysis](#part-g-outlier-analysis) | [Model 3: ClosePrice Challenge](#modeling-part-3-challenge-of-using-closeprice) |
| [Part c: Categorical Analysis](#part-c-explore-categorical-variables-vs-competitive-auctions) | [Part h: Data Partitioning](#part-h-data-partitioning-60-train-40-test) | [Model 4: Without ClosePrice](#modeling-part-4-model-without-closeprice) |
| [Part d: Class Balance](#part-d-class-balance-analysis) | | [Key Findings](#summary-of-key-findings) |
| | | [**Summary Answers**](#summary-answers-to-questions) |
| | | [Conclusion](#conclusion) |

---

## Business Problem

The file `eBayAuctions.csv` contains information on 1972 auctions transacted on eBay.com during May-June 2004. The goal is to use these data to build a model that will distinguish competitive auctions from noncompetitive ones.

A **competitive auction** is defined as an auction with at least two bids placed on the item being auctioned.

## Part a: Import Packages and Load Data

```{python}
import numpy as np
import pandas as pd
import sklearn as sk
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
import statsmodels.api as sm
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

# Load the dataset
ebay_df = pd.read_csv('eBayAuctions.csv')

print(f"Dataset loaded: {ebay_df.shape[0]} rows, {ebay_df.shape[1]} columns")
print("\nFirst 5 rows of the dataset:")
ebay_df.head()
```

## Part b: Observe Variables in the Dataset

```{python}
print("--- Data Types ---")
print(ebay_df.dtypes)
```

```{python}
print("--- Summary Statistics ---")
ebay_df.describe()
```

```{python}
print("--- Info about the dataset ---")
ebay_df.info()
```

## Part c: Explore Categorical Variables vs Competitive Auctions

### Category Analysis

```{python}
print("--- Competitive Auctions by Category ---")
category_competitive = ebay_df.groupby('Category')['Competitive'].agg(['mean', 'count'])
category_competitive = category_competitive.sort_values('mean', ascending=False)
print(category_competitive)
print(f"\nCategory with MOST competitive auctions: {category_competitive['mean'].idxmax()} "
      f"({category_competitive['mean'].max():.2%} competitive rate)")
```

### Currency Analysis

```{python}
print("--- Competitive Auctions by Currency ---")
currency_competitive = ebay_df.groupby('currency')['Competitive'].agg(['mean', 'count'])
currency_competitive
```

### End Day Analysis

```{python}
print("--- Competitive Auctions by End Day ---")
endday_competitive = ebay_df.groupby('endDay')['Competitive'].agg(['mean', 'count'])
endday_competitive = endday_competitive.sort_values('mean', ascending=False)
print(endday_competitive)
print(f"\nDay with MOST competitive auctions: {endday_competitive['mean'].idxmax()} "
      f"({endday_competitive['mean'].max():.2%} competitive rate)")
```

### Duration Analysis

```{python}
print("--- Competitive Auctions by Duration ---")
duration_competitive = ebay_df.groupby('Duration')['Competitive'].agg(['mean', 'count'])
duration_competitive
```

## Part d: Class Balance Analysis

What percentage of auctions are competitive? Is there an imbalance problem?

```{python}
competitive_counts = ebay_df.groupby('Competitive')['Competitive'].agg(['count'])
print("--- Count of Competitive vs Non-Competitive Auctions ---")
print(competitive_counts)

total = competitive_counts['count'].sum()
competitive_pct = competitive_counts.loc[1, 'count'] / total * 100
non_competitive_pct = competitive_counts.loc[0, 'count'] / total * 100

print(f"\nCompetitive auctions: {competitive_pct:.2f}%")
print(f"Non-competitive auctions: {non_competitive_pct:.2f}%")

if abs(competitive_pct - 50) > 10:
    print(f"\n‚ö†Ô∏è  There appears to be a CLASS IMBALANCE issue.")
    print(f"   The classes are not evenly distributed ({competitive_pct:.1f}% vs {non_competitive_pct:.1f}%)")
else:
    print("\n‚úì The classes are relatively balanced.")
```

```{python}
# Violin plot: Distribution of OpenPrice by Competitive Status (outliers removed)
# Remove outliers using IQR method
Q1 = ebay_df['OpenPrice'].quantile(0.25)
Q3 = ebay_df['OpenPrice'].quantile(0.75)
IQR = Q3 - Q1
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

# Filter data to remove outliers
ebay_filtered = ebay_df[(ebay_df['OpenPrice'] >= lower_bound) & (ebay_df['OpenPrice'] <= upper_bound)].copy()
print(f"Removed {len(ebay_df) - len(ebay_filtered)} outliers from {len(ebay_df)} records")

# Create labels for the filtered data
ebay_filtered['Competitive_Label'] = ebay_filtered['Competitive'].map({0: 'Non-Competitive', 1: 'Competitive'})

plt.figure(figsize=(10, 6))
sns.violinplot(x='Competitive_Label', y='OpenPrice', data=ebay_filtered, 
               hue='Competitive_Label', palette=['#E74C3C', '#27AE60'], inner='box', legend=False)
plt.xlabel('Auction Type', fontsize=12)
plt.ylabel('Opening Price ($)', fontsize=12)
plt.title('Distribution of Opening Price: Competitive vs Non-Competitive Auctions\n(Outliers Removed)', fontsize=14)
plt.tight_layout()
plt.show()
```

## Part e: Converting Variables to Category Type

```{python}
# Create a copy for modeling
ebay_model = ebay_df.copy()

# Convert to category type
ebay_model['currency'] = ebay_model['currency'].astype('category')
ebay_model['endDay'] = ebay_model['endDay'].astype('category')
ebay_model['Category'] = ebay_model['Category'].astype('category')
ebay_model['Competitive'] = ebay_model['Competitive'].astype('category')

print("Variable types after conversion:")
print(ebay_model.dtypes)
```

## Part f: Creating Dummy Variables

```{python}
# Create dummy variables (dtype=int for statsmodels compatibility)
ebay_model = pd.get_dummies(ebay_model, prefix_sep='_', drop_first=False, dtype=int)

print(f"Shape after creating dummies: {ebay_model.shape}")
print("\nColumns after creating dummies:")
print(ebay_model.columns.tolist())
```

```{python}
# Drop reference categories (first category for each variable)
# Category_Automotive, currency_EUR, endDay_Mon
columns_to_drop = ['Category_Automotive', 'currency_EUR', 'endDay_Mon', 
                   'Competitive_0']  # Also drop one of the Competitive dummies

# Check which columns exist before dropping
existing_cols = [col for col in columns_to_drop if col in ebay_model.columns]
ebay_model.drop(columns=existing_cols, inplace=True)

# Rename Competitive_1 to Competitive
if 'Competitive_1' in ebay_model.columns:
    ebay_model.rename(columns={'Competitive_1': 'Competitive'}, inplace=True)

print(f"Shape after dropping reference categories: {ebay_model.shape}")
print("\nFinal columns for modeling:")
print(ebay_model.columns.tolist())
```

## Part g: Outlier Analysis

```{python}
# Identify outliers using IQR method for numerical columns (but keep them in the dataset)
numerical_cols = ['OpenPrice', 'ClosePrice', 'sellerRating']

print(f"Dataset size: {len(ebay_model)}")
print("\nOutlier detection using IQR method:")

for col in numerical_cols:
    Q1 = ebay_model[col].quantile(0.25)
    Q3 = ebay_model[col].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    
    outliers_in_col = ((ebay_model[col] < lower_bound) | (ebay_model[col] > upper_bound)).sum()
    print(f"  {col}: {outliers_in_col} outliers detected (range: {lower_bound:.2f} to {upper_bound:.2f})")

print("\n‚úì Outliers are KEPT in the dataset for modeling.")
```

## Part h: Data Partitioning (60% Train / 40% Test)

```{python}
# Define X (features) and y (target)
# Convert y to int to ensure compatibility with statsmodels
y = ebay_model['Competitive'].astype(int)
X = ebay_model.drop(columns=['Competitive'])

# Split the data with random_state=202
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.40, random_state=202
)

print(f"Training set size: {len(X_train)} ({len(X_train)/len(X)*100:.1f}%)")
print(f"Test set size: {len(X_test)} ({len(X_test)/len(X)*100:.1f}%)")
```

## Modeling Part 1: Logistic Regression with ALL Variables

```{python}
# Using statsmodels for detailed output
X_train_const = sm.add_constant(X_train)
X_test_const = sm.add_constant(X_test)

# Fit logistic regression using 'bfgs' method to avoid singular matrix issues
logit_model = sm.Logit(y_train, X_train_const)
result = logit_model.fit(method='bfgs', disp=0)

print("--- Logistic Regression Summary (with all variables including ClosePrice) ---")
print(result.summary())
```

```{python}
# Using sklearn for predictions
lr_model = LogisticRegression(max_iter=1000, random_state=202)
lr_model.fit(X_train, y_train)
```

## Modeling Part 2: Confusion Matrix and Accuracy

```{python}
# Predictions on test set
y_pred = lr_model.predict(X_test)

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
print("--- Confusion Matrix (Validation Data) ---")
print(f"                 Predicted")
print(f"                 0       1")
print(f"Actual 0      {cm[0,0]:4d}    {cm[0,1]:4d}")
print(f"       1      {cm[1,0]:4d}    {cm[1,1]:4d}")

# Accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f"\nAccuracy: {accuracy:.4f} ({accuracy*100:.2f}%)")
```

```{python}
# Confusion Matrix Plot
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
            xticklabels=['Non-Competitive (0)', 'Competitive (1)'],
            yticklabels=['Non-Competitive (0)', 'Competitive (1)'],
            annot_kws={'size': 14})
plt.xlabel('Predicted', fontsize=12)
plt.ylabel('Actual', fontsize=12)
plt.title('Confusion Matrix (With ClosePrice)', fontsize=14)
plt.tight_layout()
plt.show()
```

```{python}
# Classification Report
print("--- Classification Report ---")
print(classification_report(y_test, y_pred))
```

## Modeling Part 3: Challenge of Using ClosePrice

**ANSWER:** The challenge of using ClosePrice to predict if an auction will be competitive is that ClosePrice is **NOT AVAILABLE** at the time of prediction.

### Key Issues:

1. **DATA LEAKAGE:** ClosePrice is determined AFTER the auction ends, which means it is influenced by whether the auction was competitive or not. Using it as a predictor creates data leakage - we're using information that wouldn't be available when making predictions on new auctions.

2. **CAUSALITY:** Higher close prices often result FROM competitive bidding. This reverses the causal relationship - the outcome (competitive auction) causes the predictor (higher close price), not the other way around.

3. **PRACTICAL UTILITY:** In a real-world scenario, we want to predict whether an auction WILL BE competitive before it happens. ClosePrice is only known after the auction concludes, making it useless for prospective predictions.

This is why we need to build a model WITHOUT ClosePrice for practical use.

## Modeling Part 4: Model WITHOUT ClosePrice

```{python}
# Remove ClosePrice from features
X_no_close = X.drop(columns=['ClosePrice'])

# Split again with same random state
X_train_nc, X_test_nc, y_train_nc, y_test_nc = train_test_split(
    X_no_close, y, test_size=0.40, random_state=202
)

# Fit new model without ClosePrice
lr_model_nc = LogisticRegression(max_iter=1000, random_state=202)
lr_model_nc.fit(X_train_nc, y_train_nc)

# Predictions
y_pred_nc = lr_model_nc.predict(X_test_nc)
```

```{python}
# Confusion Matrix
cm_nc = confusion_matrix(y_test_nc, y_pred_nc)
print("--- Confusion Matrix WITHOUT ClosePrice ---")
print(f"                 Predicted")
print(f"                 0       1")
print(f"Actual 0      {cm_nc[0,0]:4d}    {cm_nc[0,1]:4d}")
print(f"       1      {cm_nc[1,0]:4d}    {cm_nc[1,1]:4d}")

# New Accuracy
accuracy_nc = accuracy_score(y_test_nc, y_pred_nc)
print(f"\nAccuracy WITHOUT ClosePrice: {accuracy_nc:.4f} ({accuracy_nc*100:.2f}%)")
```

```{python}
# Confusion Matrix Plot (Without ClosePrice)
plt.figure(figsize=(8, 6))
sns.heatmap(cm_nc, annot=True, fmt='d', cmap='Oranges', 
            xticklabels=['Non-Competitive (0)', 'Competitive (1)'],
            yticklabels=['Non-Competitive (0)', 'Competitive (1)'],
            annot_kws={'size': 14})
plt.xlabel('Predicted', fontsize=12)
plt.ylabel('Actual', fontsize=12)
plt.title('Confusion Matrix (Without ClosePrice)', fontsize=14)
plt.tight_layout()
plt.show()
```

```{python}
# Change in accuracy
accuracy_change = accuracy_nc - accuracy
print(f"--- Comparison ---")
print(f"Accuracy WITH ClosePrice:    {accuracy:.4f} ({accuracy*100:.2f}%)")
print(f"Accuracy WITHOUT ClosePrice: {accuracy_nc:.4f} ({accuracy_nc*100:.2f}%)")
print(f"Change in Accuracy:          {accuracy_change:.4f} ({accuracy_change*100:.2f}%)")

if accuracy_change < 0:
    print(f"\n‚ö†Ô∏è  Accuracy DECREASED by {abs(accuracy_change)*100:.2f}% after removing ClosePrice.")
    print("   This confirms that ClosePrice was contributing significantly to the model,")
    print("   but for practical predictions, the model without ClosePrice is more appropriate.")
else:
    print(f"\n‚úì Accuracy changed by {accuracy_change*100:.2f}% after removing ClosePrice.")
```

```{python}
# Classification Report for model without ClosePrice
print("--- Classification Report (Without ClosePrice) ---")
print(classification_report(y_test_nc, y_pred_nc))
```

```{python}
# Statsmodels summary for the model without ClosePrice
print("--- Logistic Regression Summary (Without ClosePrice) ---")
X_train_nc_const = sm.add_constant(X_train_nc)
logit_model_nc = sm.Logit(y_train_nc, X_train_nc_const)
result_nc = logit_model_nc.fit(method='bfgs', disp=0)
print(result_nc.summary())
```

## Summary of Key Findings

This section summarizes the key findings from our analysis by answering the critical questions about eBay auction competitiveness.

```{python}
# Calculate training accuracies (not just validation)
# Model WITH ClosePrice - Training Accuracy
y_train_pred = lr_model.predict(X_train)
train_accuracy_with_close = accuracy_score(y_train, y_train_pred)

# Model WITHOUT ClosePrice - Training Accuracy  
y_train_pred_nc = lr_model_nc.predict(X_train_nc)
train_accuracy_without_close = accuracy_score(y_train_nc, y_train_pred_nc)

# Store validation accuracies (already calculated)
val_accuracy_with_close = accuracy
val_accuracy_without_close = accuracy_nc

print("=" * 70)
print("SUMMARY OF KEY FINDINGS")
print("=" * 70)
```

### Q1: Which category has the most competitive auctions? Which day of week?

```{python}
# Category with most competitive auctions
print("üìä CATEGORY ANALYSIS:")
print(f"   Category with MOST competitive auctions: {category_competitive['mean'].idxmax()}")
print(f"   Competitive Rate: {category_competitive['mean'].max():.2%}")
print()

# Day of week with most competitive auctions
print("üìÖ DAY OF WEEK ANALYSIS:")
print(f"   Day with MOST competitive auctions: {endday_competitive['mean'].idxmax()}")
print(f"   Competitive Rate: {endday_competitive['mean'].max():.2%}")
```

### Q2: What percentage of auctions are competitive?

```{python}
total_auctions = len(ebay_df)
competitive_auctions = ebay_df['Competitive'].sum()
competitive_percentage = (competitive_auctions / total_auctions) * 100

print("üìà COMPETITIVE AUCTION PERCENTAGE:")
print(f"   Total Auctions: {total_auctions}")
print(f"   Competitive Auctions: {competitive_auctions}")
print(f"   Percentage Competitive: {competitive_percentage:.2f}%")
```

### Q3: Is there an imbalance problem?

```{python}
print("‚öñÔ∏è CLASS IMBALANCE ANALYSIS:")
print(f"   Competitive: {competitive_percentage:.2f}%")
print(f"   Non-Competitive: {100 - competitive_percentage:.2f}%")
print()

# Check for imbalance (typically if minority class < 40% or > 60%)
if competitive_percentage < 40 or competitive_percentage > 60:
    print("   ‚ö†Ô∏è  YES - There IS an imbalance problem.")
    print(f"   The classes are not evenly balanced ({competitive_percentage:.1f}% vs {100-competitive_percentage:.1f}%)")
    print("   This could affect model performance, particularly for the minority class.")
else:
    print("   ‚úì NO - The classes are relatively balanced.")
```

### Q4-Q7: Model Accuracy Comparison

```{python}
print("üéØ MODEL ACCURACY SUMMARY:")
print("-" * 50)
print()
print("WITH ClosePrice:")
print(f"   Q4. Training Accuracy:   {train_accuracy_with_close:.4f} ({train_accuracy_with_close*100:.2f}%)")
print(f"   Q5. Validation Accuracy: {val_accuracy_with_close:.4f} ({val_accuracy_with_close*100:.2f}%)")
print()
print("WITHOUT ClosePrice:")
print(f"   Q6. Training Accuracy:   {train_accuracy_without_close:.4f} ({train_accuracy_without_close*100:.2f}%)")
print(f"   Q7. Validation Accuracy: {val_accuracy_without_close:.4f} ({val_accuracy_without_close*100:.2f}%)")
```

### Q8: Change in accuracy between with and without ClosePrice

```{python}
train_accuracy_change = train_accuracy_without_close - train_accuracy_with_close
val_accuracy_change = val_accuracy_without_close - val_accuracy_with_close

print("üìâ ACCURACY CHANGE (Without ClosePrice - With ClosePrice):")
print("-" * 50)
print(f"   Training Accuracy Change:   {train_accuracy_change:.4f} ({train_accuracy_change*100:.2f}%)")
print(f"   Validation Accuracy Change: {val_accuracy_change:.4f} ({val_accuracy_change*100:.2f}%)")
print()
if val_accuracy_change < 0:
    print(f"   ‚ö†Ô∏è  Removing ClosePrice DECREASED validation accuracy by {abs(val_accuracy_change)*100:.2f}%")
    print("   However, this is the more appropriate model for real-world predictions")
    print("   since ClosePrice is not available before the auction ends.")
else:
    print(f"   ‚úì Removing ClosePrice changed validation accuracy by {val_accuracy_change*100:.2f}%")
```

### Summary Table

```{python}
# Create a summary DataFrame
summary_data = {
    'Metric': [
        'Most Competitive Category',
        'Most Competitive Day',
        'Competitive Auction %',
        'Imbalance Problem?',
        'Training Accuracy (with ClosePrice)',
        'Validation Accuracy (with ClosePrice)',
        'Training Accuracy (without ClosePrice)',
        'Validation Accuracy (without ClosePrice)',
        'Validation Accuracy Change'
    ],
    'Value': [
        category_competitive['mean'].idxmax(),
        endday_competitive['mean'].idxmax(),
        f"{competitive_percentage:.2f}%",
        "Yes" if (competitive_percentage < 40 or competitive_percentage > 60) else "No",
        f"{train_accuracy_with_close*100:.2f}%",
        f"{val_accuracy_with_close*100:.2f}%",
        f"{train_accuracy_without_close*100:.2f}%",
        f"{val_accuracy_without_close*100:.2f}%",
        f"{val_accuracy_change*100:.2f}%"
    ]
}

summary_df = pd.DataFrame(summary_data)
print("\n" + "=" * 70)
print("COMPLETE SUMMARY TABLE")
print("=" * 70)
summary_df
```

---

## Summary Answers to Questions

```{python}
#| echo: false

# Create comprehensive summary answers
print("=" * 75)
print("SUMMARY ANSWERS TO ALL QUESTIONS")
print("=" * 75)
print()

# Question A/B
print("PART A & B: DATA LOADING AND OBSERVATION")
print("-" * 75)
print(f"‚Ä¢ Dataset contains {len(ebay_df):,} auction records with {ebay_df.shape[1]} variables")
print(f"‚Ä¢ Variables include: {', '.join(ebay_df.columns[:5].tolist())}...")
print()

# Question C
print("PART C: CATEGORICAL VARIABLE ANALYSIS")
print("-" * 75)
print(f"‚Ä¢ Category with MOST competitive auctions: {category_competitive['mean'].idxmax()} ({category_competitive['mean'].max():.2%})")
print(f"‚Ä¢ Day with MOST competitive auctions: {endday_competitive['mean'].idxmax()} ({endday_competitive['mean'].max():.2%})")
print()

# Question D
print("PART D: CLASS BALANCE ANALYSIS")
print("-" * 75)
print(f"‚Ä¢ Percentage of competitive auctions: {competitive_percentage:.2f}%")
print(f"‚Ä¢ Percentage of non-competitive auctions: {100 - competitive_percentage:.2f}%")
imbalance = "YES" if (competitive_percentage < 40 or competitive_percentage > 60) else "NO"
print(f"‚Ä¢ Is there an imbalance problem? {imbalance}")
print()

# Questions E-H (Data Preparation)
print("PARTS E-H: DATA PREPARATION")
print("-" * 75)
print(f"‚Ä¢ Variables converted to category type: currency, endDay, Category, Competitive")
print(f"‚Ä¢ Dummy variables created for categorical predictors")
print(f"‚Ä¢ Reference categories dropped: Category_Automotive, currency_EUR, endDay_Mon")
print(f"‚Ä¢ Training set size: {len(X_train)} (60%)")
print(f"‚Ä¢ Test set size: {len(X_test)} (40%)")
print()

# Model Accuracies
print("MODEL ACCURACY RESULTS")
print("-" * 75)
print("Model WITH ClosePrice:")
print(f"   ‚Ä¢ Training Accuracy:   {train_accuracy_with_close:.4f} ({train_accuracy_with_close*100:.2f}%)")
print(f"   ‚Ä¢ Validation Accuracy: {val_accuracy_with_close:.4f} ({val_accuracy_with_close*100:.2f}%)")
print()
print("Model WITHOUT ClosePrice:")
print(f"   ‚Ä¢ Training Accuracy:   {train_accuracy_without_close:.4f} ({train_accuracy_without_close*100:.2f}%)")
print(f"   ‚Ä¢ Validation Accuracy: {val_accuracy_without_close:.4f} ({val_accuracy_without_close*100:.2f}%)")
print()

# Change in Accuracy
print("CHANGE IN ACCURACY (After Removing ClosePrice)")
print("-" * 75)
print(f"   ‚Ä¢ Training Accuracy Change:   {train_accuracy_change:+.4f} ({train_accuracy_change*100:+.2f}%)")
print(f"   ‚Ä¢ Validation Accuracy Change: {val_accuracy_change:+.4f} ({val_accuracy_change*100:+.2f}%)")
print()

# ClosePrice Challenge
print("CHALLENGE OF USING CLOSEPRICE")
print("-" * 75)
print("   ClosePrice creates DATA LEAKAGE because:")
print("   1. ClosePrice is only known AFTER the auction ends")
print("   2. Competitive bidding CAUSES higher close prices (reversed causality)")
print("   3. Cannot be used for predictions on NEW/upcoming auctions")
print()

print("=" * 75)
```

```{python}
#| echo: false

# Create a formatted answers table that displays properly
from IPython.display import display, HTML

imbalance_answer = "Yes" if (competitive_percentage < 40 or competitive_percentage > 60) else "No"

answers_df = pd.DataFrame({
    'Question': [
        'Most competitive category?',
        'Most competitive day?',
        '% of auctions competitive?',
        'Imbalance problem?',
        'Training accuracy (with ClosePrice)?',
        'Validation accuracy (with ClosePrice)?',
        'Training accuracy (without ClosePrice)?',
        'Validation accuracy (without ClosePrice)?',
        'Accuracy change after removing ClosePrice?'
    ],
    'Answer': [
        category_competitive['mean'].idxmax(),
        endday_competitive['mean'].idxmax(),
        f"{competitive_percentage:.2f}%",
        imbalance_answer,
        f"{train_accuracy_with_close*100:.2f}%",
        f"{val_accuracy_with_close*100:.2f}%",
        f"{train_accuracy_without_close*100:.2f}%",
        f"{val_accuracy_without_close*100:.2f}%",
        f"{val_accuracy_change*100:+.2f}%"
    ]
})

# Display the answers table
display(answers_df.style.set_properties(**{'text-align': 'left'}).hide(axis='index'))
```

---

## Conclusion

This analysis built logistic regression models to predict competitive eBay auctions. The key finding is that while including ClosePrice improves accuracy, it creates a data leakage problem since ClosePrice is only known after an auction ends. The practical model (without ClosePrice) should be used for real-world predictions.

### Advantages of Removing ClosePrice

While the model without ClosePrice has lower accuracy, removing this variable provides several important advantages:

1. **Eliminates Data Leakage:** ClosePrice is determined by the auction outcome itself. By removing it, we ensure our model only uses information that would be available BEFORE the auction concludes, making predictions legitimate and unbiased.

2. **Enables Real-Time Predictions:** Without ClosePrice, the model can be deployed to predict competitiveness for NEW auctions as soon as they are listed. Sellers can use this to make informed decisions about their listings before any bids are placed.

3. **Honest Performance Evaluation:** The accuracy of the model without ClosePrice reflects the TRUE predictive power we can expect in practice. The inflated accuracy from including ClosePrice was misleading and would not generalize to real-world applications.

4. **Proper Causal Interpretation:** The remaining predictors (OpenPrice, Duration, Category, etc.) represent genuine factors that INFLUENCE competitiveness, rather than variables that are CAUSED BY competitiveness. This maintains the correct causal direction for prediction.

5. **Actionable Business Insights:** The model now identifies factors that sellers can actually control or consider when listing items (e.g., starting price, auction duration, listing day), providing actionable recommendations for maximizing auction competitiveness.